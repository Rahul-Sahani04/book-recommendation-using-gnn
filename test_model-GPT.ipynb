{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/l7z1pz590c340yqzvk57pbw00000gn/T/ipykernel_14370/3838673073.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv('data/Books.csv')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load datasets\n",
    "books = pd.read_csv('data/Books.csv')\n",
    "ratings = pd.read_csv('data/Ratings.csv')\n",
    "users = pd.read_csv('data/Users.csv')\n",
    "\n",
    "# Encode User-ID and ISBN to numerical values\n",
    "user_encoder = LabelEncoder()\n",
    "book_encoder = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[445839, 1], edge_index=[2, 1149780], edge_attr=[1149780])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ratings['User-ID'] = user_encoder.fit_transform(ratings['User-ID'])\n",
    "ratings['ISBN'] = book_encoder.fit_transform(ratings['ISBN'])\n",
    "\n",
    "# Create node feature matrices (dummy features for now)\n",
    "num_users = ratings['User-ID'].max() + 1\n",
    "num_books = ratings['ISBN'].max() + 1\n",
    "\n",
    "# Features: Initialize dummy features (1 for all nodes)\n",
    "user_features = torch.ones((num_users, 1))\n",
    "book_features = torch.ones((num_books, 1))\n",
    "\n",
    "\n",
    "# Combine user and book features\n",
    "x = torch.cat([user_features, book_features], dim=0)\n",
    "\n",
    "# Create edge index and edge attributes (ratings as weights)\n",
    "user_indices = torch.tensor(ratings['User-ID'].values, dtype=torch.long)\n",
    "book_indices = torch.tensor(ratings['ISBN'].values + num_users, dtype=torch.long)  # Offset book indices\n",
    "edge_index = torch.stack([user_indices, book_indices], dim=0)\n",
    "\n",
    "# Edge weights: Ratings normalized between 0 and 1\n",
    "edge_attr = torch.tensor(ratings['Book-Rating'].values / ratings['Book-Rating'].max(), dtype=torch.float)\n",
    "\n",
    "# Build PyTorch Geometric graph\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class BookGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BookGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_attr)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight=edge_attr)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/l7z1pz590c340yqzvk57pbw00000gn/T/ipykernel_14370/3766858327.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('models/book_gnn_model-1731667954.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BookGNN(\n",
       "  (conv1): GCNConv(1, 64)\n",
       "  (conv2): GCNConv(64, 16)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the model, loss, and optimizer\n",
    "input_dim = 1  # Initial feature size\n",
    "hidden_dim = 64\n",
    "output_dim = 16  # Embedding size\n",
    "\n",
    "# Load the model\n",
    "model = BookGNN(input_dim, hidden_dim, output_dim)\n",
    "model.load_state_dict(torch.load('models/book_gnn_model-1731667954.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a test dataset similar to the training dataset\n",
    "test_ratings = pd.read_csv('data/TestRatings.csv')\n",
    "\n",
    "# Convert User-ID and ISBN to strings before combining\n",
    "ratings['User-ID'] = ratings['User-ID'].astype(str)\n",
    "ratings['ISBN'] = ratings['ISBN'].astype(str)\n",
    "test_ratings['User-ID'] = test_ratings['User-ID'].astype(str)\n",
    "test_ratings['ISBN'] = test_ratings['ISBN'].astype(str)\n",
    "\n",
    "# Combine training and test data for encoding\n",
    "combined_user_ids = pd.concat([ratings['User-ID'], test_ratings['User-ID']])\n",
    "combined_isbns = pd.concat([ratings['ISBN'], test_ratings['ISBN']])\n",
    "\n",
    "# Fit the encoders on the combined data\n",
    "user_encoder.fit(combined_user_ids)\n",
    "book_encoder.fit(combined_isbns)\n",
    "\n",
    "# Encode User-ID and ISBN to numerical values using the same encoders\n",
    "test_ratings['User-ID'] = user_encoder.transform(test_ratings['User-ID'])\n",
    "test_ratings['ISBN'] = book_encoder.transform(test_ratings['ISBN'])\n",
    "\n",
    "# Create edge index and edge attributes for the test data\n",
    "test_user_indices = torch.tensor(test_ratings['User-ID'].values, dtype=torch.long)\n",
    "test_book_indices = torch.tensor(test_ratings['ISBN'].values + num_users, dtype=torch.long)  # Offset book indices\n",
    "test_edge_index = torch.stack([test_user_indices, test_book_indices], dim=0)\n",
    "test_edge_attr = torch.tensor(test_ratings['Book-Rating'].values / test_ratings['Book-Rating'].max(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Forward pass\n",
    "    out = model(data.x, data.edge_index, data.edge_attr)\n",
    "    \n",
    "    # Get embeddings for test edges\n",
    "    test_user_embeddings = out[test_edge_index[0]]\n",
    "    test_book_embeddings = out[test_edge_index[1]]\n",
    "    \n",
    "    # Predict ratings\n",
    "    predicted_ratings = torch.sum(test_user_embeddings * test_book_embeddings, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.405109703540802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Compute the mean squared error between predicted and actual ratings\n",
    "mse = mean_squared_error(test_edge_attr.numpy(), predicted_ratings.numpy())\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original User ID: 100106\n"
     ]
    }
   ],
   "source": [
    "# Example: Get the original user ID from the encoded user ID\n",
    "encoded_user_id = 123  # This is the numerical ID used in the model\n",
    "original_user_id = user_encoder.inverse_transform([encoded_user_id])[0]\n",
    "print(f'Original User ID: {original_user_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['142626' '175015' '1369' '250026' '229710' '12533' '32266' '108666'\n",
      " '197748' '207504']\n"
     ]
    }
   ],
   "source": [
    "def recommend_books(user_id, top_n=10):\n",
    "    user_id_str = str(user_id)\n",
    "    if user_id_str not in user_encoder.classes_:\n",
    "        print(f\"User ID {user_id} not found in the encoder.\")\n",
    "        return []\n",
    "    \n",
    "    user_node = user_encoder.transform([user_id_str])[0]\n",
    "    user_embedding = out[user_node].unsqueeze(0)\n",
    "    \n",
    "    # Compute similarity scores with all book embeddings\n",
    "    scores = torch.matmul(user_embedding, out[num_users:].t()).squeeze()\n",
    "    \n",
    "    # Get top N book indices\n",
    "    _, top_book_indices = torch.topk(scores, top_n)\n",
    "    \n",
    "    # Decode book indices to original ISBNs\n",
    "    recommended_books = book_encoder.inverse_transform(top_book_indices.numpy())\n",
    "    return recommended_books\n",
    "\n",
    "# Example: Recommend top 10 books for user with ID 99998\n",
    "recommended_books = recommend_books(99998, top_n=10)\n",
    "print(recommended_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '10' ... '99997' '99998' '99999']\n"
     ]
    }
   ],
   "source": [
    "print(user_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ISBN, Book-Title, Book-Author, Year-Of-Publication, Publisher, Image-URL-S, Image-URL-M, Image-URL-L]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data of books from the dataset based on the indices\n",
    "books_data = books[books['ISBN'].isin(recommended_books)]\n",
    "\n",
    "books_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/l7z1pz590c340yqzvk57pbw00000gn/T/ipykernel_14370/314993916.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv('data/Books.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the book data\n",
    "books = pd.read_csv('data/Books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(user_id, top_n=10):\n",
    "    user_id_str = str(user_id)\n",
    "    if user_id_str not in user_encoder.classes_:\n",
    "        print(f\"User ID {user_id} not found in the encoder.\")\n",
    "        return []\n",
    "    \n",
    "    user_node = user_encoder.transform([user_id_str])[0]\n",
    "    user_embedding = out[user_node].unsqueeze(0)\n",
    "    \n",
    "    # Compute similarity scores with all book embeddings\n",
    "    scores = torch.matmul(user_embedding, out[len(users):].t()).squeeze()\n",
    "    \n",
    "    # Get top N book indices\n",
    "    _, top_book_indices = torch.topk(scores, top_n)\n",
    "    \n",
    "    # Decode book indices to original ISBNs\n",
    "    recommended_books = book_encoder.inverse_transform(top_book_indices.numpy())\n",
    "    return recommended_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ISBNs: ['166442' '121610' '107673' '125814' '167130' '140630' '127165' '172344'\n",
      " '132100' '107078']\n",
      "Empty DataFrame\n",
      "Columns: [ISBN, Book-Title, Book-Author, Year-Of-Publication, Publisher, Image-URL-S, Image-URL-M, Image-URL-L]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Example: Recommend top 10 books for user with ID 99998\n",
    "recommended_books_isbns = recommend_books(99998, top_n=10)\n",
    "\n",
    "# Print the recommended ISBNs\n",
    "print(\"Recommended ISBNs:\", recommended_books_isbns)\n",
    "\n",
    "# Filter the book data to include only the recommended books\n",
    "recommended_books_data = books[books['ISBN'].isin(recommended_books_isbns)]\n",
    "\n",
    "# Print the filtered book data\n",
    "print(recommended_books_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166442\n",
      "121610\n",
      "107673\n",
      "125814\n",
      "167130\n",
      "140630\n",
      "127165\n",
      "172344\n",
      "132100\n",
      "107078\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for row_num in recommended_books_isbns:\n",
    "    print(int(row_num))\n",
    "    result.append(books.loc[int(row_num)].values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0865475156',\n",
       "       \"Last Night's Fun: In and Out of Time With Irish Music\",\n",
       "       'Ciaran Carson', 1997, 'Farrar Straus &amp; Giroux',\n",
       "       'http://images.amazon.com/images/P/0865475156.01.THUMBZZZ.jpg',\n",
       "       'http://images.amazon.com/images/P/0865475156.01.MZZZZZZZ.jpg',\n",
       "       'http://images.amazon.com/images/P/0865475156.01.LZZZZZZZ.jpg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find a book by its row number\n",
    "book_row = 167130\n",
    "\n",
    "# Get the ISBN of the book\n",
    "book_isbn = books.loc[book_row].values\n",
    "book_isbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['0374503168', 'Christ Stopped at Eboli: The Story of a Year',\n",
       "        'Carlo Levi', 1995, 'Farrar Straus Giroux',\n",
       "        'http://images.amazon.com/images/P/0374503168.01.THUMBZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0374503168.01.MZZZZZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0374503168.01.LZZZZZZZ.jpg'],\n",
       "       dtype=object),\n",
       " array(['0061063223', 'Slime Time (BC 10) (Bone Chillers)', 'Betsy Haynes',\n",
       "        1996, 'HarperTorch',\n",
       "        'http://images.amazon.com/images/P/0061063223.01.THUMBZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0061063223.01.MZZZZZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0061063223.01.LZZZZZZZ.jpg'],\n",
       "       dtype=object),\n",
       " array(['0933635516',\n",
       "        'Cthulhu Now: Modern Adventures and Background for Call of Cthulhu Roleplaying/3307',\n",
       "        'William A. Barton', 1992, 'Chaosium',\n",
       "        'http://images.amazon.com/images/P/0933635516.01.THUMBZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0933635516.01.MZZZZZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0933635516.01.LZZZZZZZ.jpg'],\n",
       "       dtype=object),\n",
       " array(['8472237850', 'La Muerte De Belle', 'Georges Simenon', 2002,\n",
       "        'Tusquets',\n",
       "        'http://images.amazon.com/images/P/8472237850.01.THUMBZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/8472237850.01.MZZZZZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/8472237850.01.LZZZZZZZ.jpg'],\n",
       "       dtype=object),\n",
       " array(['0865475156',\n",
       "        \"Last Night's Fun: In and Out of Time With Irish Music\",\n",
       "        'Ciaran Carson', 1997, 'Farrar Straus &amp; Giroux',\n",
       "        'http://images.amazon.com/images/P/0865475156.01.THUMBZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0865475156.01.MZZZZZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0865475156.01.LZZZZZZZ.jpg'],\n",
       "       dtype=object),\n",
       " array(['0816737819', 'Sonic &amp; Knuckles', 'Michael Teitelbaum', 1995,\n",
       "        'Troll Communications',\n",
       "        'http://images.amazon.com/images/P/0816737819.01.THUMBZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0816737819.01.MZZZZZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0816737819.01.LZZZZZZZ.jpg'],\n",
       "       dtype=object),\n",
       " array(['1590580834', 'The Edge of the Gulf', 'Hadley Hury', 2003,\n",
       "        'Poisoned Pen Press',\n",
       "        'http://images.amazon.com/images/P/1590580834.01.THUMBZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/1590580834.01.MZZZZZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/1590580834.01.LZZZZZZZ.jpg'],\n",
       "       dtype=object),\n",
       " array(['0553268805', 'Greatest Salesman in the World', 'Og Mandino', 1983,\n",
       "        'Bantam Books',\n",
       "        'http://images.amazon.com/images/P/0553268805.01.THUMBZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0553268805.01.MZZZZZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0553268805.01.LZZZZZZZ.jpg'],\n",
       "       dtype=object),\n",
       " array(['0373290810', \"Doctor'S Wife (Harlequin Historical, No. 481)\",\n",
       "        'Cheryl St. John', 1999, 'Harlequin',\n",
       "        'http://images.amazon.com/images/P/0373290810.01.THUMBZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0373290810.01.MZZZZZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0373290810.01.LZZZZZZZ.jpg'],\n",
       "       dtype=object),\n",
       " array(['0751507660', 'Sharper Knives', 'Christopher Fowler', 1994,\n",
       "        'Little Brown Uk',\n",
       "        'http://images.amazon.com/images/P/0751507660.01.THUMBZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0751507660.01.MZZZZZZZ.jpg',\n",
       "        'http://images.amazon.com/images/P/0751507660.01.LZZZZZZZ.jpg'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book-recommendation-using-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
